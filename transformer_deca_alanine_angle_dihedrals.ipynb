{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Transformer on Deca-alanine IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where only the bonds are modeled by a univariate Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributions as dist\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os\n",
    "from einops import rearrange\n",
    "from torch import nn, einsum\n",
    "\n",
    "#Custom\n",
    "import utilities\n",
    "torch.max_split_size_mb = 2048\n",
    "import time\n",
    "import pickle\n",
    "from mixture_of_experts import MoE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dataset, Calculate Means and Covariances of Bonds and Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_bucketize(input_, num_bins, lower_bound = -torch.pi, upper_bound = torch.pi, right=True):\n",
    "    bounds = torch.linspace(start=lower_bound, end=upper_bound, steps=num_bins).to(device)\n",
    "    return torch.bucketize(input_, bounds).to(device)\n",
    "\n",
    "def un_bucketize_dict(num_bins, lower_bound = -torch.pi, upper_bound = torch.pi):\n",
    "    unbucket_dict = dict()\n",
    "    data_range = upper_bound - lower_bound\n",
    "    delta = data_range/num_bins\n",
    "    lower_value = lower_bound + delta/2\n",
    "    \n",
    "    for iter in range(0, num_bins+1, 1):\n",
    "        unbucket_dict[iter] = lower_value\n",
    "        lower_value = lower_value + delta\n",
    "        \n",
    "    return unbucket_dict\n",
    "\n",
    "def un_bucketize(input_, num_bins, device=torch.device('cuda:0'), \n",
    "                 lower_bound = -torch.pi, upper_bound = torch.pi):\n",
    "    unbucket_dict = un_bucketize_dict(num_bins, lower_bound=-torch.pi, upper_bound=torch.pi)\n",
    "    np_input = input_.cpu().numpy()\n",
    "    return torch.tensor( np.vectorize(unbucket_dict.get)(np_input) ).to(device)\n",
    "\n",
    "def statistical_unbucketize(input_, num_bins, lower_bound=-torch.pi, upper_bound=torch.pi):\n",
    "    \"\"\"Unbucketize in a sampling operation\"\"\"\n",
    "    data_linspace = torch.linspace(start=lower_bound, end=upper_bound, steps=GLOBAL_NUM_BINS+1)\n",
    "\n",
    "    uniform_dist_dict = dict()\n",
    "    data_range = 2*torch.pi\n",
    "    delta = data_range/GLOBAL_NUM_BINS\n",
    "    \n",
    "    np_input = input_.cpu().numpy()\n",
    "    \n",
    "    for iter in range(0, GLOBAL_NUM_BINS, 1):\n",
    "        lower_range = data_linspace[iter]\n",
    "        upper_range = data_linspace[iter+1]\n",
    "        uniform_dist_dict[iter] = torch.distributions.Uniform(lower_range, upper_range)\n",
    "    \n",
    "    sample_item = lambda item: item.sample()\n",
    "    #resol = np.vectorize(sample_item)(result) \n",
    "\n",
    "    dist_array =  np.vectorize(uniform_dist_dict.get)(np_input)\n",
    "    return np.vectorize(sample_item)(dist_array) \n",
    "\n",
    "def return_unimodal_multimodal(flattened_data):\n",
    "    flattened_data = flattened_data.to(device)\n",
    "    bonds_angles = flattened_data[:, :-99].to(device)\n",
    "    dihedrals = flattened_data[:, 201:].to(device)\n",
    "    \n",
    "    unimodal_dihedrals = torch.index_select(dihedrals, 1, unimodal_indx).to(device)\n",
    "    pi_dihedrals = torch.index_select(dihedrals, 1, pi_indx).to(device)\n",
    "    multi_dihedrals = torch.index_select(dihedrals, 1, multimodal_indx).to(device)\n",
    "    unimodal_data = torch.cat([bonds_angles, unimodal_dihedrals, pi_dihedrals], dim=1).to(device)\n",
    "    \n",
    "    return unimodal_data, multi_dihedrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_HIDDEN_SIZE = 512\n",
    "GLOBAL_NUM_BINS = 700\n",
    "GLOBAL_DROPOUT = 0.00\n",
    "GLOBAL_NUM_ATTN_HEADS = 4\n",
    "GLOBAL_QKV_DEPTH = 128 #GLOBAL_HIDDEN_SIZE/GLOBAL_NUM_ATTN_HEADS\n",
    "GLOBAL_BATCH_SIZE = 512\n",
    "#decoder_specific\n",
    "GLOBAL_DECODER_EXPERTS = 6\n",
    "GLOBAL_DECODER_LAYERS = 6\n",
    "#encoder_specific\n",
    "GLOBAL_ENCODER_LAYERS = 2\n",
    "GLOBAL_ENCODER_FILTER_SIZE = GLOBAL_HIDDEN_SIZE*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    }
   ],
   "source": [
    "MMCD_path = \"./\"\n",
    "sys.path.append(MMCD_path)\n",
    "from mmcd import MMCDataset\n",
    "\n",
    "name = 'decaalanine'\n",
    "data_path = os.path.join(MMCD_path, \"data\")\n",
    "\n",
    "dataset_train = MMCDataset(root = data_path,\n",
    "                           molecule_name = name,\n",
    "                           train = True,\n",
    "                           coordinate_type = 'internal',\n",
    "                           lazy_load = False)\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          num_workers = 1,\n",
    "                          batch_size = GLOBAL_BATCH_SIZE, #256 is the default batch size\n",
    "                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bonds_dist(data, dec=False):\n",
    "    if dec==False:\n",
    "        bonds = data[:, :-19] \n",
    "    else:\n",
    "        bonds = data[:, :-198] #deccalanine has 99 dihedrals and 99 angles\n",
    "        \n",
    "    bonds = bonds.permute(1, 0)\n",
    "    np_bonds = np.array(bonds)\n",
    "    covar_mat = np.cov(np_bonds)\n",
    "    means = np.mean(np_bonds, axis = 1)\n",
    "    tr_covar = torch.tensor(covar_mat).double()\n",
    "    tr_means = torch.tensor(means).double()\n",
    "    bonds_dist = dist.MultivariateNormal(loc = tr_means, covariance_matrix = tr_covar)\n",
    "    \n",
    "    del tr_covar\n",
    "    del tr_means \n",
    "    \n",
    "    return bonds_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwhole_loader = DataLoader(dataset_train,\\n    num_workers = 1,\\n    batch_size = 160000, #256 is the default batch size\\n    shuffle = True)\\n\\nfor batch_idx, (data, _) in enumerate(whole_loader):\\n    #Flatten the data into a tensor of size (256, 60) tensor before putting it into the GPU\\n    data = utilities.flatten_data(data) #for deccalanine\\n    bonds_dist = return_bonds_dist(data, dec=True)\\n\\nwith open('bond_dist.pickle', 'wb') as dist_file:\\n    pickle.dump(bonds_dist, dist_file)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "whole_loader = DataLoader(dataset_train,\n",
    "    num_workers = 1,\n",
    "    batch_size = 160000, #256 is the default batch size\n",
    "    shuffle = True)\n",
    "\n",
    "for batch_idx, (data, _) in enumerate(whole_loader):\n",
    "    #Flatten the data into a tensor of size (256, 60) tensor before putting it into the GPU\n",
    "    data = utilities.flatten_data(data) #for deccalanine\n",
    "    bonds_dist = return_bonds_dist(data, dec=True)\n",
    "\n",
    "with open('bond_dist.pickle', 'wb') as dist_file:\n",
    "    pickle.dump(bonds_dist, dist_file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"bond_dist.pickle\", \"rb\")\n",
    "bonds_dist = pickle.load(file_to_read)\n",
    "file_to_read.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### Encoder, Decoder ###\n",
    "########################\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"Implements a single layer of an unconditional ImageTransformer\"\"\"\n",
    "    def __init__(self):\n",
    "        self.hidden_size = GLOBAL_HIDDEN_SIZE\n",
    "\n",
    "        super().__init__()\n",
    "        self.attn = Attn()\n",
    "        self.dropout = nn.Dropout(p=GLOBAL_DROPOUT)\n",
    "        self.layernorm_attn = nn.LayerNorm([self.hidden_size], eps=1e-6, elementwise_affine=True)\n",
    "        self.layernorm_attn2 = nn.LayerNorm([self.hidden_size], eps=1e-6, elementwise_affine=True)\n",
    "        self.layernorm_ffn = nn.LayerNorm([self.hidden_size], eps=1e-6, elementwise_affine=True)\n",
    "        \n",
    "        self.MoE = MoE(\n",
    "            dim = GLOBAL_HIDDEN_SIZE,\n",
    "            num_experts = GLOBAL_DECODER_EXPERTS, # increase the experts (# parameters) of your model without increasing computation\n",
    "            hidden_dim = GLOBAL_HIDDEN_SIZE * 4, #size of hidden dimension in each expert, defaults to 4 * dimension\n",
    "            activation = nn.LeakyReLU,      # use your preferred activation, will default to GELU\n",
    "            second_policy_train = 'random', # in top_2 gating, policy for whether to use a second-place expert\n",
    "            second_policy_eval = 'random',  # all (always) | none (never) | threshold (if gate value > the given threshold) | random (if gate value > threshold * random_uniform(0, 1))\n",
    "            second_threshold_train = 0.2,\n",
    "            second_threshold_eval = 0.2,\n",
    "            capacity_factor_train = 1.25,   # experts have fixed capacity per batch. we need some extra capacity in case gating is not perfectly balanced.\n",
    "            capacity_factor_eval = 2.,      # capacity_factor_* should be set to a value >=1\n",
    "            loss_coef = 1e-2                # multiplier on the auxiliary expert balancing auxiliary loss\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, X, encoder_output=None):\n",
    "        #the first layer of a decoder is just normal self-attention\n",
    "        y = self.attn(X, use_encoder_output=False, autoregressive_mask=True)\n",
    "        X = self.layernorm_attn(self.dropout(y) + X)\n",
    "        #the second layer of a decoder uses outputs from the encoder as query and key values\n",
    "        y = self.attn(X, encoder_output=encoder_output, \n",
    "            use_encoder_output=True, autoregressive_mask=True)\n",
    "        X = self.layernorm_attn2(self.dropout(y) + X)\n",
    "        #but note that both attentions need masking\n",
    "        y, _ = self.MoE(X)\n",
    "        X = self.layernorm_ffn(self.dropout(y) + X)\n",
    "        return X\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"The encoder is also identical to the decoder, except that the decoder has masking operation\" \n",
    "    def __init__(self):\n",
    "        self.hidden_size = GLOBAL_HIDDEN_SIZE\n",
    "        self.filter_size = GLOBAL_ENCODER_FILTER_SIZE\n",
    "        super().__init__()\n",
    "        self.attn = Attn()\n",
    "        self.dropout = nn.Dropout(p=GLOBAL_DROPOUT)\n",
    "        self.layernorm_attn = nn.LayerNorm([self.hidden_size], eps=1e-6, elementwise_affine=True)\n",
    "        self.layernorm_ffn = nn.LayerNorm([self.hidden_size], eps=1e-6, elementwise_affine=True)\n",
    "        self.ffn = nn.Sequential(nn.Linear(self.hidden_size, self.filter_size, bias=True),\n",
    "                   nn.ReLU(), nn.Linear(self.filter_size, self.hidden_size, bias=True))\n",
    "\n",
    "    def forward(self, X):\n",
    "        y = self.attn(X, autoregressive_mask=False)\n",
    "        X = self.layernorm_attn(self.dropout(y) + X)\n",
    "        y = self.ffn(X)\n",
    "        X = self.layernorm_ffn(self.dropout(y) + X)\n",
    "        return X\n",
    "\n",
    "############\n",
    "### Attn ###\n",
    "############\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = GLOBAL_HIDDEN_SIZE\n",
    "        self.num_heads = GLOBAL_NUM_ATTN_HEADS\n",
    "        self.kd = GLOBAL_QKV_DEPTH*self.num_heads\n",
    "        self.vd = GLOBAL_QKV_DEPTH*self.num_heads\n",
    "\n",
    "        self.q_dense = nn.Linear(self.hidden_size, self.kd, bias=False)\n",
    "        self.k_dense = nn.Linear(self.hidden_size, self.kd, bias=False)\n",
    "        self.v_dense = nn.Linear(self.hidden_size, self.vd, bias=False)\n",
    "        self.output_dense = nn.Linear(self.vd, self.hidden_size, bias=False)\n",
    "        \n",
    "        assert self.kd % self.num_heads == 0\n",
    "        assert self.vd % self.num_heads == 0\n",
    "\n",
    "    def dot_product_attention(self, q, k, v, bias=None):\n",
    "        logits = torch.einsum(\"...kd,...qd->...qk\", k, q)\n",
    "        if bias is not None:\n",
    "            logits += bias\n",
    "        weights = F.softmax(logits, dim=-1)\n",
    "        return weights @ v\n",
    "\n",
    "    def forward(self, X, encoder_output=None, autoregressive_mask=True, use_encoder_output=False):\n",
    "        if use_encoder_output == False: \n",
    "            q = self.q_dense(X)\n",
    "            k = self.k_dense(X)\n",
    "            v = self.v_dense(X)\n",
    "        elif use_encoder_output == True: \n",
    "            v = self.v_dense(X)\n",
    "            q = self.q_dense(encoder_output.clone())\n",
    "            k = self.k_dense(encoder_output.clone())\n",
    "\n",
    "        #Split to shape [batch_size, num_heads, len, depth / num_heads]\n",
    "        q = q.view(q.shape[:-1] + (self.num_heads, self.kd // self.num_heads)).permute([0, 2, 1, 3])\n",
    "        k = k.view(k.shape[:-1] + (self.num_heads, self.kd // self.num_heads)).permute([0, 2, 1, 3])\n",
    "        v = v.view(v.shape[:-1] + (self.num_heads, self.vd // self.num_heads)).permute([0, 2, 1, 3])\n",
    "        q *= (self.kd // self.num_heads) ** (-0.5) #normalized dot product or something\n",
    "        \n",
    "        if autoregressive_mask == True: \n",
    "            bias = -1e10*torch.triu(torch.ones(X.shape[1], X.shape[1]), 1).to(X.device)\n",
    "            result = self.dot_product_attention(q, k, v, bias=bias)\n",
    "        elif autoregressive_mask == False: \n",
    "            result = self.dot_product_attention(q, k, v, bias=None)\n",
    "\n",
    "        result = result.permute([0, 2, 1, 3]).contiguous()\n",
    "        result = result.view(result.shape[0:2] + (-1,))\n",
    "        result = self.output_dense(result)\n",
    "        return result\n",
    "\n",
    "##########################\n",
    "### Actual Transformer ###\n",
    "##########################\n",
    "\n",
    "class TransformerIC(nn.Module):\n",
    "    def __init__(self, given_dist):\n",
    "        super(TransformerIC, self).__init__()\n",
    "        #model specific params\n",
    "        self.hidden_size = GLOBAL_HIDDEN_SIZE\n",
    "        self.num_bins = GLOBAL_NUM_BINS\n",
    "        self.dropout = GLOBAL_DROPOUT\n",
    "        self.dnlayers = GLOBAL_DECODER_LAYERS\n",
    "        self.enlayers = GLOBAL_ENCODER_LAYERS\n",
    "        #data specific params\n",
    "        self.batch_size = GLOBAL_BATCH_SIZE\n",
    "        self.num_encoder_dim = 102 #99+3\n",
    "        self.num_decoder_dim = 198 #99\n",
    "        #given unimodal dist\n",
    "        self.encoder_dist = given_dist\n",
    "        #functions\n",
    "        self.output_function = torch.nn.Softmax(dim=1)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.loss_function_no_sum = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        #model components\n",
    "        self.embeds = nn.Embedding(self.num_bins, self.hidden_size)\n",
    "        self.input_dropout = nn.Dropout(self.dropout)\n",
    "        self.output_dense = nn.Linear(self.hidden_size, self.num_bins, bias=True)\n",
    "        self.decoderlayers = nn.ModuleList([DecoderLayer() for _ in range(self.dnlayers)])\n",
    "        self.encoderlayers = nn.ModuleList([EncoderLayer() for _ in range(self.enlayers)])\n",
    "        self.pos_embedder_1 = torch.nn.Embedding(self.num_decoder_dim, \n",
    "            self.hidden_size) #decoder pos embedding\n",
    "        #reshape encoder output\n",
    "        self.pos_embedder_0 = torch.nn.Embedding(self.num_decoder_dim, self.hidden_size) #encoder_positional_encoding\n",
    "        self.vd = GLOBAL_QKV_DEPTH \n",
    "        self.encoder_embeds = nn.Linear(self.num_encoder_dim, self.hidden_size*self.num_decoder_dim)\n",
    "        self.encoder_reshape = nn.Linear(self.hidden_size, self.vd, bias=False)\n",
    "    \n",
    "    def shift_and_pad_(self, X): \n",
    "        \"\"\"For the purpose of autoregressive property. Shift inputs over by 1 and pad.\n",
    "        x should be [256, 19, 8]. Pad 2nd to last dimension, \n",
    "        since 1st dimension is batch and last is embedding.\"\"\"\n",
    "        X = X[:, :-1, :]\n",
    "        X = F.pad(X, (0, 0, 1, 0)) #kinda need to figure out how this works\n",
    "        return X\n",
    "\n",
    "    def forward(self, decoder_input=None, encoder_input=None, encoder_output=None, sampling=False, return_encoder=False):\n",
    "        #activates the decoder only\n",
    "        if encoder_output == None:\n",
    "            encoder_output = self.encoder_embeds(encoder_input)\n",
    "            #normalize properly\n",
    "            encoder_output = encoder_output.view((encoder_input.shape[0], \n",
    "                self.num_decoder_dim, self.hidden_size)) * (self.hidden_size ** 0.5)\n",
    "            #inject positional information for encoder\n",
    "            pos_index = torch.arange(0, self.num_decoder_dim).repeat(encoder_input.size()[0], 1).to(device)\n",
    "            pos_embeddings = self.pos_embedder_0(pos_index)\n",
    "            encoder_output = pos_embeddings + encoder_output\n",
    "            #pass through encoder layers\n",
    "            for layer in self.encoderlayers:\n",
    "                encoder_output = layer(encoder_output)\n",
    "            if return_encoder == True:\n",
    "                return encoder_output\n",
    "            \n",
    "        #not used in training, but used by sapling\n",
    "        if sampling:\n",
    "            curr_infer_length = decoder_input.shape[1]\n",
    "            decoder_input = F.pad(decoder_input, (0, self.num_decoder_dim - curr_infer_length))  \n",
    "            \n",
    "        #apply embedding and shift and pad\n",
    "        decoder_input = self.shift_and_pad_(self.embeds(decoder_input) * (self.hidden_size ** 0.5))\n",
    "        #apply positional embedding\n",
    "        pos_index = torch.arange(0, self.num_decoder_dim).repeat(decoder_input.size()[0], 1).to(device)\n",
    "        decoder_input = decoder_input + self.pos_embedder_1(pos_index)\n",
    "        \n",
    "        for layer in self.decoderlayers:\n",
    "            decoder_input = layer(decoder_input, encoder_output = encoder_output) \n",
    "        \n",
    "        decoder_input = self.output_dense(decoder_input) \n",
    "        \n",
    "        return decoder_input\n",
    "\n",
    "    def sample(self, batch_size, device, detach=False): #batch size is num samples\n",
    "        \"\"\"sampling procedure does not require gradients\"\"\"\n",
    "        encoder_data = self.encoder_dist.sample(torch.tensor([batch_size])).to(device).float()\n",
    "        encoder_output = self.forward(decoder_input=None, encoder_input=encoder_data, return_encoder=True)\n",
    "        \n",
    "        if detach==True:\n",
    "            encoder_data = encoder_data.detach()\n",
    "\n",
    "        total_len = self.num_decoder_dim\n",
    "        samples = torch.zeros((batch_size, 1)).to(device).long()\n",
    "        \n",
    "        if detach == True:\n",
    "            samples = samples.detach()\n",
    "\n",
    "        for curr_infer_length in range(total_len):\n",
    "            outputs = self.forward(decoder_input=samples, encoder_output=encoder_output, \n",
    "                                   sampling=True)\n",
    "            \n",
    "            outputs = outputs[:, curr_infer_length]\n",
    "            \n",
    "            categorical = self.output_function(outputs) #outputs is energy\n",
    "            temp_distribution = dist.Categorical(torch.squeeze(categorical))\n",
    "            x = temp_distribution.sample()\n",
    "            x = x.unsqueeze(dim=1)#print(categorical.size()) = [10, 629]\n",
    "            if curr_infer_length == 0:\n",
    "                samples = x\n",
    "            else:\n",
    "                samples = torch.cat([samples, x], 1)\n",
    "\n",
    "        return encoder_data, samples\n",
    "\n",
    "    def loss(self, X, Y, with_energy=False, reduce=True):\n",
    "        #X is a categorical distribution and Y is the target (one hot encoding).\n",
    "        X = X.permute(0, 2, 1)\n",
    "        #X.size() = [256, 19, 629] after permuting; Y.size() = [256, 19]\n",
    "        #256 = batchsize, 629 = number classes, 19 = number of dihedrals\n",
    "        if reduce==False:\n",
    "            return self.loss_function_no_sum(X, Y)\n",
    "        loss_value = self.loss_function(X, Y) #nn.CrossEntropyLoss automatically applies softmax\n",
    "        return loss_value\n",
    "    \n",
    "    def exact_log_likelihood(self, ba, dihedrals):\n",
    "        #dihedrals should be represented as indicies already\n",
    "        dist = self.forward(dihedrals=dihedrals, ba=ba)\n",
    "        #dist = dist.permute(0, 2, 1)\n",
    "        ba_loss = self.unimodal_dist.log_prob(ba.cpu())\n",
    "        dihedral_loss = self.loss(dist.to(device), dihedrals.to(device), reduce=False).to(device) #+ \\\n",
    "        #self.ba_dist.log_prob(ba.to(device)).to(device)    \n",
    "        dihedral_loss = torch.sum(dihedral_loss, dim=1)\n",
    "        loss = torch.add(ba_loss.to(device), dihedral_loss.to(device))\n",
    "        return loss\n",
    "\n",
    "    def energy_loss(self, batch_size, device, sum=False):\n",
    "        ba, dihedral = model.sample(batch_size, device=device)\n",
    "        dihedral_true = utilities.index_to_number(dihedral)\n",
    "        q_s = (-model.exact_log_likelihood(ba=ba, dihedrals=dihedral))\n",
    "        E_s = dataset_train.compute_potential_energy_for_ic(\n",
    "            utilities.rebuild(\n",
    "                torch.cat([ba, dihedral_true], dim=1).cpu().detach()\n",
    "            ), unitless=False\n",
    "        )\n",
    "        return torch.sum(torch.add(torch.tensor(E_s).to(device), q_s.to(device)))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = TransformerIC(given_dist = bonds_dist).to(device)\n",
    "#bonds = torch.randn((GLOBAL_BATCH_SIZE, 102)).to(device)\n",
    "#decoder = torch.ones((GLOBAL_BATCH_SIZE, 198)).to(device).long()\n",
    "#model.forward(decoder_input = decoder, encoder_input = bonds)\n",
    "#res = model.sample(64, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)\n",
    "\n",
    "global_loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_parallel(X, Y):\n",
    "    X = X.permute(0, 2, 1)\n",
    "    return global_loss_function(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"angles_dihedrals_decoder_state_dict.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/slurm_tmp/19420469.0.0/ipykernel_46119/3313736123.py:3: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484803030/work/aten/src/ATen/native/BucketizationUtils.h:33.)\n",
      "  return torch.bucketize(input_, bounds).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/313 (0%)]\tLoss: 0.007277\n",
      "Train Epoch: 0 [50/313 (16%)]\tLoss: 0.007301\n",
      "Train Epoch: 0 [100/313 (32%)]\tLoss: 0.007294\n",
      "Train Epoch: 0 [150/313 (48%)]\tLoss: 0.007295\n",
      "Train Epoch: 0 [200/313 (64%)]\tLoss: 0.007291\n",
      "Train Epoch: 0 [250/313 (80%)]\tLoss: 0.007300\n",
      "Train Epoch: 0 [300/313 (96%)]\tLoss: 0.007288\n",
      "Train Epoch: 1 [0/313 (0%)]\tLoss: 0.007297\n",
      "Train Epoch: 1 [50/313 (16%)]\tLoss: 0.007290\n",
      "Train Epoch: 1 [100/313 (32%)]\tLoss: 0.007287\n",
      "Train Epoch: 1 [150/313 (48%)]\tLoss: 0.007298\n",
      "Train Epoch: 1 [200/313 (64%)]\tLoss: 0.007287\n",
      "Train Epoch: 1 [250/313 (80%)]\tLoss: 0.007289\n",
      "Train Epoch: 1 [300/313 (96%)]\tLoss: 0.007296\n",
      "Train Epoch: 2 [0/313 (0%)]\tLoss: 0.007284\n",
      "Train Epoch: 2 [50/313 (16%)]\tLoss: 0.007286\n",
      "Train Epoch: 2 [100/313 (32%)]\tLoss: 0.007282\n",
      "Train Epoch: 2 [150/313 (48%)]\tLoss: 0.007278\n",
      "Train Epoch: 2 [200/313 (64%)]\tLoss: 0.007292\n",
      "Train Epoch: 2 [250/313 (80%)]\tLoss: 0.007290\n",
      "Train Epoch: 2 [300/313 (96%)]\tLoss: 0.007291\n",
      "Train Epoch: 3 [0/313 (0%)]\tLoss: 0.007280\n",
      "Train Epoch: 3 [50/313 (16%)]\tLoss: 0.007277\n",
      "Train Epoch: 3 [100/313 (32%)]\tLoss: 0.007283\n",
      "Train Epoch: 3 [150/313 (48%)]\tLoss: 0.007282\n",
      "Train Epoch: 3 [200/313 (64%)]\tLoss: 0.007281\n",
      "Train Epoch: 3 [250/313 (80%)]\tLoss: 0.007277\n",
      "Train Epoch: 3 [300/313 (96%)]\tLoss: 0.007273\n",
      "Train Epoch: 4 [0/313 (0%)]\tLoss: 0.007281\n",
      "Train Epoch: 4 [50/313 (16%)]\tLoss: 0.007282\n",
      "Train Epoch: 4 [100/313 (32%)]\tLoss: 0.007260\n",
      "Train Epoch: 4 [150/313 (48%)]\tLoss: 0.007280\n",
      "Train Epoch: 4 [200/313 (64%)]\tLoss: 0.007272\n",
      "Train Epoch: 4 [250/313 (80%)]\tLoss: 0.007270\n",
      "Train Epoch: 4 [300/313 (96%)]\tLoss: 0.007274\n",
      "Train Epoch: 5 [0/313 (0%)]\tLoss: 0.007275\n",
      "Train Epoch: 5 [50/313 (16%)]\tLoss: 0.007270\n",
      "Train Epoch: 5 [100/313 (32%)]\tLoss: 0.007269\n",
      "Train Epoch: 5 [150/313 (48%)]\tLoss: 0.007265\n",
      "Train Epoch: 5 [200/313 (64%)]\tLoss: 0.007269\n",
      "Train Epoch: 5 [250/313 (80%)]\tLoss: 0.007273\n",
      "Train Epoch: 5 [300/313 (96%)]\tLoss: 0.007265\n",
      "Train Epoch: 6 [0/313 (0%)]\tLoss: 0.007263\n",
      "Train Epoch: 6 [50/313 (16%)]\tLoss: 0.007250\n",
      "Train Epoch: 6 [100/313 (32%)]\tLoss: 0.007268\n",
      "Train Epoch: 6 [150/313 (48%)]\tLoss: 0.007261\n",
      "Train Epoch: 6 [200/313 (64%)]\tLoss: 0.007260\n",
      "Train Epoch: 6 [250/313 (80%)]\tLoss: 0.007268\n",
      "Train Epoch: 6 [300/313 (96%)]\tLoss: 0.007261\n",
      "Train Epoch: 7 [0/313 (0%)]\tLoss: 0.007261\n",
      "Train Epoch: 7 [50/313 (16%)]\tLoss: 0.007260\n",
      "Train Epoch: 7 [100/313 (32%)]\tLoss: 0.007252\n",
      "Train Epoch: 7 [150/313 (48%)]\tLoss: 0.007260\n",
      "Train Epoch: 7 [200/313 (64%)]\tLoss: 0.007267\n",
      "Train Epoch: 7 [250/313 (80%)]\tLoss: 0.007258\n",
      "Train Epoch: 7 [300/313 (96%)]\tLoss: 0.007252\n",
      "Train Epoch: 8 [0/313 (0%)]\tLoss: 0.007256\n",
      "Train Epoch: 8 [50/313 (16%)]\tLoss: 0.007257\n",
      "Train Epoch: 8 [100/313 (32%)]\tLoss: 0.007257\n",
      "Train Epoch: 8 [150/313 (48%)]\tLoss: 0.007251\n",
      "Train Epoch: 8 [200/313 (64%)]\tLoss: 0.007261\n",
      "Train Epoch: 8 [250/313 (80%)]\tLoss: 0.007251\n",
      "Train Epoch: 8 [300/313 (96%)]\tLoss: 0.007254\n",
      "Train Epoch: 9 [0/313 (0%)]\tLoss: 0.007255\n",
      "Train Epoch: 9 [50/313 (16%)]\tLoss: 0.007246\n",
      "Train Epoch: 9 [100/313 (32%)]\tLoss: 0.007239\n",
      "Train Epoch: 9 [150/313 (48%)]\tLoss: 0.007251\n",
      "Train Epoch: 9 [200/313 (64%)]\tLoss: 0.007253\n",
      "Train Epoch: 9 [250/313 (80%)]\tLoss: 0.007251\n",
      "Train Epoch: 9 [300/313 (96%)]\tLoss: 0.007235\n",
      "Train Epoch: 10 [0/313 (0%)]\tLoss: 0.007258\n",
      "Train Epoch: 10 [50/313 (16%)]\tLoss: 0.007240\n",
      "Train Epoch: 10 [100/313 (32%)]\tLoss: 0.007243\n",
      "Train Epoch: 10 [150/313 (48%)]\tLoss: 0.007250\n",
      "Train Epoch: 10 [200/313 (64%)]\tLoss: 0.007244\n",
      "Train Epoch: 10 [250/313 (80%)]\tLoss: 0.007252\n",
      "Train Epoch: 10 [300/313 (96%)]\tLoss: 0.007252\n",
      "Train Epoch: 11 [0/313 (0%)]\tLoss: 0.007247\n",
      "Train Epoch: 11 [50/313 (16%)]\tLoss: 0.007246\n",
      "Train Epoch: 11 [100/313 (32%)]\tLoss: 0.007246\n",
      "Train Epoch: 11 [150/313 (48%)]\tLoss: 0.007252\n",
      "Train Epoch: 11 [200/313 (64%)]\tLoss: 0.007255\n",
      "Train Epoch: 11 [250/313 (80%)]\tLoss: 0.007243\n",
      "Train Epoch: 11 [300/313 (96%)]\tLoss: 0.007251\n",
      "Train Epoch: 12 [0/313 (0%)]\tLoss: 0.007234\n",
      "Train Epoch: 12 [50/313 (16%)]\tLoss: 0.007252\n",
      "Train Epoch: 12 [100/313 (32%)]\tLoss: 0.007248\n",
      "Train Epoch: 12 [150/313 (48%)]\tLoss: 0.007254\n",
      "Train Epoch: 12 [200/313 (64%)]\tLoss: 0.007245\n",
      "Train Epoch: 12 [250/313 (80%)]\tLoss: 0.007250\n",
      "Train Epoch: 12 [300/313 (96%)]\tLoss: 0.007248\n",
      "Train Epoch: 13 [0/313 (0%)]\tLoss: 0.007244\n",
      "Train Epoch: 13 [50/313 (16%)]\tLoss: 0.007239\n",
      "Train Epoch: 13 [100/313 (32%)]\tLoss: 0.007242\n",
      "Train Epoch: 13 [150/313 (48%)]\tLoss: 0.007242\n",
      "Train Epoch: 13 [200/313 (64%)]\tLoss: 0.007257\n",
      "Train Epoch: 13 [250/313 (80%)]\tLoss: 0.007246\n",
      "Train Epoch: 13 [300/313 (96%)]\tLoss: 0.007246\n",
      "Train Epoch: 14 [0/313 (0%)]\tLoss: 0.007248\n",
      "Train Epoch: 14 [50/313 (16%)]\tLoss: 0.007250\n",
      "Train Epoch: 14 [100/313 (32%)]\tLoss: 0.007248\n",
      "Train Epoch: 14 [150/313 (48%)]\tLoss: 0.007242\n",
      "Train Epoch: 14 [200/313 (64%)]\tLoss: 0.007254\n",
      "Train Epoch: 14 [250/313 (80%)]\tLoss: 0.007249\n",
      "Train Epoch: 14 [300/313 (96%)]\tLoss: 0.007254\n",
      "Train Epoch: 15 [0/313 (0%)]\tLoss: 0.007244\n",
      "Train Epoch: 15 [50/313 (16%)]\tLoss: 0.007246\n",
      "Train Epoch: 15 [100/313 (32%)]\tLoss: 0.007262\n",
      "Train Epoch: 15 [150/313 (48%)]\tLoss: 0.007257\n",
      "Train Epoch: 15 [200/313 (64%)]\tLoss: 0.007259\n",
      "Train Epoch: 15 [250/313 (80%)]\tLoss: 0.007256\n",
      "Train Epoch: 15 [300/313 (96%)]\tLoss: 0.007267\n",
      "Train Epoch: 16 [50/313 (16%)]\tLoss: 0.007258\n",
      "Train Epoch: 16 [100/313 (32%)]\tLoss: 0.007259\n",
      "Train Epoch: 16 [150/313 (48%)]\tLoss: 0.007257\n",
      "Train Epoch: 16 [200/313 (64%)]\tLoss: 0.007259\n",
      "Train Epoch: 16 [250/313 (80%)]\tLoss: 0.007256\n",
      "Train Epoch: 16 [300/313 (96%)]\tLoss: 0.007249\n",
      "Train Epoch: 17 [0/313 (0%)]\tLoss: 0.007245\n",
      "Train Epoch: 17 [50/313 (16%)]\tLoss: 0.007246\n",
      "Train Epoch: 17 [100/313 (32%)]\tLoss: 0.007251\n",
      "Train Epoch: 17 [150/313 (48%)]\tLoss: 0.007260\n",
      "Train Epoch: 17 [200/313 (64%)]\tLoss: 0.007266\n",
      "Train Epoch: 17 [250/313 (80%)]\tLoss: 0.007261\n",
      "Train Epoch: 17 [300/313 (96%)]\tLoss: 0.007261\n",
      "Train Epoch: 18 [0/313 (0%)]\tLoss: 0.007238\n",
      "Train Epoch: 18 [50/313 (16%)]\tLoss: 0.007251\n",
      "Train Epoch: 18 [100/313 (32%)]\tLoss: 0.007253\n",
      "Train Epoch: 18 [150/313 (48%)]\tLoss: 0.007260\n",
      "Train Epoch: 18 [200/313 (64%)]\tLoss: 0.007261\n",
      "Train Epoch: 18 [250/313 (80%)]\tLoss: 0.007259\n",
      "Train Epoch: 18 [300/313 (96%)]\tLoss: 0.007264\n",
      "Train Epoch: 19 [0/313 (0%)]\tLoss: 0.007243\n",
      "Train Epoch: 19 [50/313 (16%)]\tLoss: 0.007254\n",
      "Train Epoch: 19 [100/313 (32%)]\tLoss: 0.007249\n",
      "Train Epoch: 19 [150/313 (48%)]\tLoss: 0.007257\n",
      "Train Epoch: 19 [200/313 (64%)]\tLoss: 0.007257\n",
      "Train Epoch: 19 [250/313 (80%)]\tLoss: 0.007257\n",
      "Train Epoch: 19 [300/313 (96%)]\tLoss: 0.007263\n",
      "Train Epoch: 20 [0/313 (0%)]\tLoss: 0.007243\n",
      "Train Epoch: 20 [50/313 (16%)]\tLoss: 0.007244\n",
      "Train Epoch: 20 [100/313 (32%)]\tLoss: 0.007254\n",
      "Train Epoch: 20 [150/313 (48%)]\tLoss: 0.007243\n",
      "Train Epoch: 20 [200/313 (64%)]\tLoss: 0.007247\n",
      "Train Epoch: 20 [250/313 (80%)]\tLoss: 0.007249\n",
      "Train Epoch: 20 [300/313 (96%)]\tLoss: 0.007253\n",
      "Train Epoch: 21 [0/313 (0%)]\tLoss: 0.007230\n",
      "Train Epoch: 21 [50/313 (16%)]\tLoss: 0.007239\n",
      "Train Epoch: 21 [100/313 (32%)]\tLoss: 0.007241\n",
      "Train Epoch: 21 [150/313 (48%)]\tLoss: 0.007252\n",
      "Train Epoch: 21 [200/313 (64%)]\tLoss: 0.007243\n",
      "Train Epoch: 21 [250/313 (80%)]\tLoss: 0.007244\n",
      "Train Epoch: 21 [300/313 (96%)]\tLoss: 0.007250\n",
      "Train Epoch: 22 [0/313 (0%)]\tLoss: 0.007225\n",
      "Train Epoch: 22 [50/313 (16%)]\tLoss: 0.007227\n",
      "Train Epoch: 22 [100/313 (32%)]\tLoss: 0.007234\n",
      "Train Epoch: 22 [150/313 (48%)]\tLoss: 0.007223\n",
      "Train Epoch: 22 [200/313 (64%)]\tLoss: 0.007228\n",
      "Train Epoch: 22 [250/313 (80%)]\tLoss: 0.007233\n",
      "Train Epoch: 22 [300/313 (96%)]\tLoss: 0.007235\n",
      "Train Epoch: 23 [0/313 (0%)]\tLoss: 0.007214\n",
      "Train Epoch: 23 [50/313 (16%)]\tLoss: 0.007218\n",
      "Train Epoch: 23 [100/313 (32%)]\tLoss: 0.007227\n",
      "Train Epoch: 23 [150/313 (48%)]\tLoss: 0.007218\n",
      "Train Epoch: 23 [200/313 (64%)]\tLoss: 0.007233\n",
      "Train Epoch: 23 [250/313 (80%)]\tLoss: 0.007230\n",
      "Train Epoch: 23 [300/313 (96%)]\tLoss: 0.007229\n",
      "Train Epoch: 24 [0/313 (0%)]\tLoss: 0.007198\n",
      "Train Epoch: 24 [50/313 (16%)]\tLoss: 0.007205\n",
      "Train Epoch: 24 [100/313 (32%)]\tLoss: 0.007221\n",
      "Train Epoch: 24 [150/313 (48%)]\tLoss: 0.007206\n",
      "Train Epoch: 24 [200/313 (64%)]\tLoss: 0.007207\n",
      "Train Epoch: 24 [250/313 (80%)]\tLoss: 0.007200\n",
      "Train Epoch: 24 [300/313 (96%)]\tLoss: 0.007220\n",
      "Train Epoch: 25 [0/313 (0%)]\tLoss: 0.007191\n",
      "Train Epoch: 25 [50/313 (16%)]\tLoss: 0.007190\n",
      "Train Epoch: 25 [100/313 (32%)]\tLoss: 0.007200\n",
      "Train Epoch: 25 [150/313 (48%)]\tLoss: 0.007195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [200/313 (64%)]\tLoss: 0.007205\n",
      "Train Epoch: 25 [250/313 (80%)]\tLoss: 0.007198\n",
      "Train Epoch: 25 [300/313 (96%)]\tLoss: 0.007213\n",
      "Train Epoch: 26 [0/313 (0%)]\tLoss: 0.007176\n",
      "Train Epoch: 26 [50/313 (16%)]\tLoss: 0.007180\n",
      "Train Epoch: 26 [100/313 (32%)]\tLoss: 0.007182\n",
      "Train Epoch: 26 [150/313 (48%)]\tLoss: 0.007188\n",
      "Train Epoch: 26 [200/313 (64%)]\tLoss: 0.007184\n",
      "Train Epoch: 26 [250/313 (80%)]\tLoss: 0.007190\n",
      "Train Epoch: 26 [300/313 (96%)]\tLoss: 0.007186\n",
      "Train Epoch: 27 [0/313 (0%)]\tLoss: 0.007174\n",
      "Train Epoch: 27 [50/313 (16%)]\tLoss: 0.007177\n",
      "Train Epoch: 27 [100/313 (32%)]\tLoss: 0.007173\n",
      "Train Epoch: 27 [150/313 (48%)]\tLoss: 0.007177\n",
      "Train Epoch: 27 [200/313 (64%)]\tLoss: 0.007170\n",
      "Train Epoch: 27 [250/313 (80%)]\tLoss: 0.007174\n",
      "Train Epoch: 27 [300/313 (96%)]\tLoss: 0.007177\n",
      "Train Epoch: 28 [0/313 (0%)]\tLoss: 0.007166\n",
      "Train Epoch: 28 [50/313 (16%)]\tLoss: 0.007155\n",
      "Train Epoch: 28 [100/313 (32%)]\tLoss: 0.007171\n",
      "Train Epoch: 28 [150/313 (48%)]\tLoss: 0.007150\n",
      "Train Epoch: 28 [200/313 (64%)]\tLoss: 0.007164\n",
      "Train Epoch: 28 [250/313 (80%)]\tLoss: 0.007163\n",
      "Train Epoch: 28 [300/313 (96%)]\tLoss: 0.007166\n",
      "Train Epoch: 29 [0/313 (0%)]\tLoss: 0.007162\n",
      "Train Epoch: 29 [50/313 (16%)]\tLoss: 0.007160\n",
      "Train Epoch: 29 [100/313 (32%)]\tLoss: 0.007155\n",
      "Train Epoch: 29 [150/313 (48%)]\tLoss: 0.007156\n",
      "Train Epoch: 29 [200/313 (64%)]\tLoss: 0.007142\n",
      "Train Epoch: 29 [250/313 (80%)]\tLoss: 0.007158\n",
      "Train Epoch: 29 [300/313 (96%)]\tLoss: 0.007148\n",
      "Train Epoch: 30 [0/313 (0%)]\tLoss: 0.007158\n",
      "Train Epoch: 30 [50/313 (16%)]\tLoss: 0.007156\n",
      "Train Epoch: 30 [100/313 (32%)]\tLoss: 0.007154\n",
      "Train Epoch: 30 [150/313 (48%)]\tLoss: 0.007152\n",
      "Train Epoch: 30 [200/313 (64%)]\tLoss: 0.007158\n",
      "Train Epoch: 30 [250/313 (80%)]\tLoss: 0.007153\n",
      "Train Epoch: 30 [300/313 (96%)]\tLoss: 0.007152\n",
      "Train Epoch: 31 [0/313 (0%)]\tLoss: 0.007153\n",
      "Train Epoch: 31 [50/313 (16%)]\tLoss: 0.007158\n",
      "Train Epoch: 31 [100/313 (32%)]\tLoss: 0.007163\n",
      "Train Epoch: 31 [150/313 (48%)]\tLoss: 0.007155\n",
      "Train Epoch: 31 [200/313 (64%)]\tLoss: 0.007159\n",
      "Train Epoch: 31 [250/313 (80%)]\tLoss: 0.007151\n",
      "Train Epoch: 31 [300/313 (96%)]\tLoss: 0.007164\n",
      "Train Epoch: 32 [0/313 (0%)]\tLoss: 0.007153\n",
      "Train Epoch: 32 [50/313 (16%)]\tLoss: 0.007150\n",
      "Train Epoch: 32 [100/313 (32%)]\tLoss: 0.007155\n",
      "Train Epoch: 32 [150/313 (48%)]\tLoss: 0.007151\n",
      "Train Epoch: 32 [200/313 (64%)]\tLoss: 0.007155\n",
      "Train Epoch: 32 [250/313 (80%)]\tLoss: 0.007161\n",
      "Train Epoch: 32 [300/313 (96%)]\tLoss: 0.007163\n",
      "Train Epoch: 33 [0/313 (0%)]\tLoss: 0.007150\n",
      "Train Epoch: 33 [50/313 (16%)]\tLoss: 0.007153\n",
      "Train Epoch: 33 [100/313 (32%)]\tLoss: 0.007164\n",
      "Train Epoch: 33 [150/313 (48%)]\tLoss: 0.007160\n",
      "Train Epoch: 33 [200/313 (64%)]\tLoss: 0.007159\n",
      "Train Epoch: 33 [250/313 (80%)]\tLoss: 0.007156\n",
      "Train Epoch: 33 [300/313 (96%)]\tLoss: 0.007158\n",
      "Train Epoch: 34 [0/313 (0%)]\tLoss: 0.007154\n",
      "Train Epoch: 34 [50/313 (16%)]\tLoss: 0.007161\n",
      "Train Epoch: 34 [100/313 (32%)]\tLoss: 0.007167\n",
      "Train Epoch: 34 [150/313 (48%)]\tLoss: 0.007172\n",
      "Train Epoch: 34 [200/313 (64%)]\tLoss: 0.007164\n",
      "Train Epoch: 34 [250/313 (80%)]\tLoss: 0.007168\n",
      "Train Epoch: 34 [300/313 (96%)]\tLoss: 0.007161\n",
      "Train Epoch: 35 [0/313 (0%)]\tLoss: 0.007152\n",
      "Train Epoch: 35 [50/313 (16%)]\tLoss: 0.007164\n",
      "Train Epoch: 35 [100/313 (32%)]\tLoss: 0.007168\n",
      "Train Epoch: 35 [150/313 (48%)]\tLoss: 0.007168\n",
      "Train Epoch: 35 [200/313 (64%)]\tLoss: 0.007163\n",
      "Train Epoch: 35 [250/313 (80%)]\tLoss: 0.007169\n",
      "Train Epoch: 35 [300/313 (96%)]\tLoss: 0.007174\n",
      "Train Epoch: 36 [0/313 (0%)]\tLoss: 0.007151\n",
      "Train Epoch: 36 [50/313 (16%)]\tLoss: 0.007157\n",
      "Train Epoch: 36 [100/313 (32%)]\tLoss: 0.007167\n",
      "Train Epoch: 36 [150/313 (48%)]\tLoss: 0.007165\n",
      "Train Epoch: 36 [200/313 (64%)]\tLoss: 0.007174\n",
      "Train Epoch: 36 [250/313 (80%)]\tLoss: 0.007168\n",
      "Train Epoch: 36 [300/313 (96%)]\tLoss: 0.007168\n",
      "Train Epoch: 37 [0/313 (0%)]\tLoss: 0.007143\n",
      "Train Epoch: 37 [50/313 (16%)]\tLoss: 0.007149\n",
      "Train Epoch: 37 [100/313 (32%)]\tLoss: 0.007174\n",
      "Train Epoch: 37 [150/313 (48%)]\tLoss: 0.007170\n",
      "Train Epoch: 37 [200/313 (64%)]\tLoss: 0.007165\n",
      "Train Epoch: 37 [250/313 (80%)]\tLoss: 0.007171\n",
      "Train Epoch: 37 [300/313 (96%)]\tLoss: 0.007177\n",
      "Train Epoch: 38 [0/313 (0%)]\tLoss: 0.007156\n",
      "Train Epoch: 38 [50/313 (16%)]\tLoss: 0.007158\n",
      "Train Epoch: 38 [100/313 (32%)]\tLoss: 0.007165\n",
      "Train Epoch: 38 [150/313 (48%)]\tLoss: 0.007161\n",
      "Train Epoch: 38 [200/313 (64%)]\tLoss: 0.007169\n",
      "Train Epoch: 38 [250/313 (80%)]\tLoss: 0.007173\n"
     ]
    }
   ],
   "source": [
    "loss_over_time = []\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10, eta_min=0, last_epoch=- 1, verbose=False)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        \n",
    "        data = utilities.flatten_data(data)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        bonds = data[:, :-99*2]\n",
    "        angles_dihedrals = data[:, 102:]\n",
    "        angles_dihedrals =  custom_bucketize(input_=angles_dihedrals, num_bins=GLOBAL_NUM_BINS)\n",
    "        true_target = angles_dihedrals\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        X_pred = model(decoder_input=angles_dihedrals, encoder_input=bonds) \n",
    "        \n",
    "        loss = loss_parallel(X=X_pred, Y=true_target) \n",
    "        total_loss = loss #+ model.energy_loss(50, device=device)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 50 == 0:#args.log_interval == 0: #by default, args.log_interval = 10\n",
    "            print('Train Epoch:', epoch, '[{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_idx, #index of the batch we are on \n",
    "                len(train_loader), #how many batches are in the data loader\n",
    "                100. * batch_idx / len(train_loader), #progress percentage\n",
    "                loss.item() / GLOBAL_BATCH_SIZE#,  #hardcoded batch size\n",
    "                ))\n",
    "        \n",
    "            loss_over_time.append(loss.item()/len(train_loader) )\n",
    "            torch.set_printoptions(threshold=10_000)\n",
    "\n",
    "for epoch in range(0, 60, 1):\n",
    "    train(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_over_time = []\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000035) \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 0.000035, eta_min=0, last_epoch=- 1, verbose=False)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        \n",
    "        data = utilities.flatten_data(data)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        bonds = data[:, :-99*2]\n",
    "        angles_dihedrals = data[:, 102:]\n",
    "        angles_dihedrals =  custom_bucketize(input_=angles_dihedrals, num_bins=GLOBAL_NUM_BINS)\n",
    "        true_target = angles_dihedrals\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        X_pred = model(decoder_input=angles_dihedrals, encoder_input=bonds) \n",
    "        \n",
    "        loss = loss_parallel(X=X_pred, Y=true_target) \n",
    "        total_loss = loss #+ model.energy_loss(50, device=device)\n",
    "        \n",
    "        total_loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:#args.log_interval == 0: #by default, args.log_interval = 10\n",
    "            print('Train Epoch:', epoch, '[{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_idx, #index of the batch we are on \n",
    "                len(train_loader), #how many batches are in the data loader\n",
    "                100. * batch_idx / len(train_loader), #progress percentage\n",
    "                loss.item() / GLOBAL_BATCH_SIZE#,  #hardcoded batch size\n",
    "                ))\n",
    "        \n",
    "            loss_over_time.append(loss.item()/len(train_loader) )\n",
    "            torch.set_printoptions(threshold=10_000)\n",
    "\n",
    "for epoch in range(0, 120, 1):\n",
    "    train(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1893\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ls = np.array(loss_over_time)\n",
    "print(np.size(ls))\n",
    "plt.plot(ls[20:])\n",
    "plt.title(\"Loss Over Time \\n Every 31 Units = 1 Epoch \\n 250 Units = 8 Epochs \\n 1750 Units = 60 Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ 3.5 \\cdot 10^{-5} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample From Model to View Distribtuions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loader = DataLoader(dataset_train,\n",
    "                          num_workers = 4,\n",
    "                          batch_size = 1000, #256 is the default batch size\n",
    "                          shuffle = True)\n",
    "\n",
    "for batch_idx, (data, _) in enumerate(sample_loader):\n",
    "    data = utilities.flatten_data(data)\n",
    "    np_data = np.array(data)\n",
    "    break\n",
    "\n",
    "del sample_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "model.to(device)\n",
    "\n",
    "ba, dihedrals = model.module.sample(100, device=device)\n",
    "for index in range(0, 19, 1):\n",
    "    print(index)\n",
    "    new_ba, new_dihedrals = model.module.sample(100, device=device)\n",
    "    ba = torch.cat([ba, new_ba], dim=0)\n",
    "    dihedrals = torch.cat([dihedrals, new_dihedrals], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dihedral_val = statistical_unbucketize(dihedrals, GLOBAL_NUM_BINS, lower_bound=-torch.pi, upper_bound=torch.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole = torch.cat([torch.tensor(ba).to(device), torch.tensor(dihedral_val).to(device)], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild(flat, data_length = 99):\n",
    "    #data_length = 19 #this is particular to dialene\n",
    "    result = {}\n",
    "    result['reference_particle_1_xyz'] = torch.zeros((flat.shape[0], 3))\n",
    "    result['reference_particle_2_bond'] = flat[:, 0]\n",
    "    result['reference_particle_3_bond'] = flat[:, 1]\n",
    "    result['reference_particle_3_angle'] = flat[:, 2]\n",
    "\n",
    "    start = 3\n",
    "    end = start + data_length\n",
    "    result['bond'] = flat[:, start:end]\n",
    "\n",
    "    start = end\n",
    "    end = start + data_length\n",
    "    result['angle'] = flat[:, start:end]\n",
    "\n",
    "    start = end\n",
    "    end = start + data_length\n",
    "    result['dihedral'] = flat[:, start:end]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = rebuild(torch.tensor(whole).to(device), data_length=99)\n",
    "potential_energy_q_theta = dataset_train.compute_potential_energy_for_ic(molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = MMCDataset(root = './data',\n",
    "                           molecule_name = name,\n",
    "                           train = False,\n",
    "                           coordinate_type = 'internal')\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test,\n",
    "                              num_workers = 8,\n",
    "                              batch_size = 1280,\n",
    "                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_energy_md = np.concatenate(\n",
    "    [dataset_train.potential_energy_kJ_per_mole,\n",
    "     dataset_test.potential_energy_kJ_per_mole]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x = np.concatenate(\n",
    "    [dataset_train.potential_energy_kJ_per_mole,\n",
    "     dataset_test.potential_energy_kJ_per_mole]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_energy_q_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(potential_energy_md[:1000], range =(0, 3000), bins = 150, alpha = 0.5, label = \"$x \\sim p_A(x)$\")\n",
    "plt.hist(potential_energy_q_theta, range =(0, 3000), bins = 150, alpha = 0.5, label = \"$x \\sim q_{\\\\theta}(x)$\")\n",
    "plt.title(\"Energy Overlap of and MD Simulations of Deca-alanine, 1000 Samples \\n Decoder Generates Angles and Dihedrals\")\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.xlabel('Energies in $kJ \\cdot mol^{-1}$')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(potential_energy_md[:1000], range =(0, 1000), bins = 150, alpha = 0.5, label = \"$x \\sim p_A(x)$\")\n",
    "plt.hist(potential_energy_q_theta, range =(0, 1000), bins = 150, alpha = 0.5, label = \"$x \\sim q_{\\\\theta}(x)$\")\n",
    "plt.title(\"Energy Overlap of and MD Simulations of Deca-alanine, 1000 Samples \\n Decoder Generates Angles and Dihedrals, 700 Bins\")\n",
    "plt.legend(prop={'size': 12})\n",
    "plt.xlabel('Energies in $kJ \\cdot mol^{-1}$')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Params: 97454780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97454780"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    #table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        #table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    #print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"angles_dihedrals_decoder_state_dict.pth\")\n",
    "torch.save(model, \"angles_dihedrals_decoder.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(x_n,...,x_1)  = p(x_n|x_{(n-1)},...,x_1) \\cdot ... \\cdot p(x_1)$$\n",
    "\n",
    "$$p(x_n,...,x_1) = \\frac{e^{-\\beta E_{\\theta}(x_n ; x...)}}{\\int_{-\\pi}^{\\pi} e^{-\\beta E_{\\theta}(x_n; x...)} dx_n} \\cdot ... \\cdot \\frac{e^{-\\beta E_{\\theta}(x)}}{\\int_{-\\pi}^{\\pi} e^{-\\beta E_{\\theta}(x)} dx}$$\n",
    "\n",
    "$$p(x_n, x_1) \\approx \\frac{e^{-\\beta E_{\\theta}(x_n; x...)}}{\\sum_{n=1}^{629} e^{-\\beta E_{\\theta}(x_n; x...)}} \\cdot ... \\cdot \\frac{e^{-\\beta E_{\\theta}(x)}}{\\sum_{n=1}^{629} e^{-\\beta E_{\\theta}(x)} }$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-UROP]",
   "language": "python",
   "name": "conda-env-.conda-UROP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6bdb4c9c3f61b306428a8735aa29fdb3d47c708c66b6a0572dccc6544bde0e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
