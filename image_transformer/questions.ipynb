{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorboardX\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "#from image_transformer import ImageTransformer\n",
    "import matplotlib\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchviz import make_dot\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 2, 1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 2])\n"
     ]
    }
   ],
   "source": [
    "X = torch.zeros(256, 60)\n",
    "print(X[: , 0:2].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are Log Probabilites Calculated Elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = torch.zeros(4, 1)\n",
    "y_2 = torch.ones(4, 1)\n",
    "y_com = torch.cat([y_1, y_2], dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_com = torch.unsqueeze(y_com, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_com.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.]],\n",
      "\n",
      "        [[0.]],\n",
      "\n",
      "        [[0.]],\n",
      "\n",
      "        [[0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(y_com[:, 0:1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([])\n",
    "q_theta = dist.VonMises(torch.squeeze(Y[:, 0, :]), torch.squeeze(Y[:, 1, :]))\n",
    "loss_sum = torch.sum(q_theta.log_prob(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Tensors Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros([256, 10, 2])\n",
    "#y = torch.zeros([256, 2, 2])\n",
    "\n",
    "h_new = torch.zeros([256, 10])\n",
    "#y_new = torch.zeros([256, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.cat([h, h_new], dim = 2)\n",
    "#y = torch.stack([y, y_new], dim = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Splicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(256, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 59:61].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Stacking Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 10]) torch.Size([16, 10])\n",
      "torch.Size([16, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "h_0  = torch.zeros(16, 10)\n",
    "h_1 = torch.zeros(16, 10)\n",
    "\n",
    "print(h_0.size(), h_1.size())\n",
    "h = torch.stack([h_0, h_1], dim = 2)\n",
    "print(h.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[:, :, 1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956],\n",
       "        [-0.4529, -0.0311,  0.4409, -0.4398, -0.5117, -0.2386,  0.1602, -0.4757,\n",
       "         -0.2209,  0.3956]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear = nn.Linear(3, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        result = self.linear(torch.cat([X, torch.zeros(64, 1)], 1))\n",
    "        return result\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = MyModule().to(device)\n",
    "model(torch.zeros(64, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModulesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=10, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.linears[0])\n",
    "        #ModuleList can act as an iterable, or be indexed using ints\n",
    "        #For index, layer in enumerate(self.linears):\n",
    "            #print(\"i: \", i), print(\"l: \", l)\n",
    "            #print(\"Hello is anyone there\")\n",
    "            #x = self.linears[index // 2](x) + layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = MyModule().to(device)\n",
    "model(torch.zeros(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#args, config = parse_args_and_config()\n",
    "#if config.model.distr == \"dmol\":\n",
    "model_image_size = 8\n",
    "model_channels = 3\n",
    "model_batch_size = 16\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(model_image_size), #model image size, so image is 8 by 8\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10('datasets/transformer', transform=transform , download=True)\n",
    "loader = DataLoader(dataset, batch_size = model_batch_size, shuffle=True, num_workers=4)\n",
    "input_dim = model_image_size ** 2 * model_channels\n",
    "#model = ImageTransformer(config.model).to(config.device)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1., betas=(0.9, 0.98), eps=1e-9)\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step: get_lr(step, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "for what, (imgs, l) in enumerate(loader):\n",
    "    imgs = imgs.to(device)\n",
    "    print(type(what))\n",
    "    print(type(imgs))\n",
    "    print(type(l))\n",
    "    break\n",
    "\n",
    "imgs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size is 16, and we have 3 channels (RGB). The images are 32 by 32. Lets examine a single image; which turns out to be a picture of a bird. \n",
    "\n",
    "Note that transforms.ToTensor() does the following:\n",
    "Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd3fa0df580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = imgs[0, :, :, :]\n",
    "img.size()\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-843588d0df97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/MMCD/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MMCD/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/MMCD/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MMCD/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MMCD/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For [categorical distributions], each of the input pixels' three color channels is encoded using a channel specific set of 256 d-dimensional embedding vectors of the intensity values 0-255. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code up a Pytorch model to generate embeddings..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the official documentation of Pytorch embeddings:\n",
    "\n",
    "num_embeddings (int) – size of the dictionary of embeddings\n",
    "\n",
    "embedding_dim (int) – the size of each embedding vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = model_image_size**2\n",
    "hidden_size = 16\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    \"\"\"ImageTransformer with DMOL or categorical distribution.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.Embedding(num_pixels * model_channels, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Embedding \n",
    "\n",
    "n_embeddings, dim = 10, 4\n",
    "\n",
    "emb_1 = Embedding(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(10, 1)\n",
      "Parameter containing:\n",
      "tensor([[-0.3890],\n",
      "        [ 1.4295],\n",
      "        [-0.6874],\n",
      "        [-0.7585],\n",
      "        [ 0.0335],\n",
      "        [-0.1820],\n",
      "        [-1.4105],\n",
      "        [-1.8211],\n",
      "        [-0.5155],\n",
      "        [ 0.4665]], requires_grad=True)\n",
      "tensor([[1],\n",
      "        [2]])\n",
      "torch.Size([2, 1])\n",
      "tensor([[[ 1.4295]],\n",
      "\n",
      "        [[-0.6874]]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(emb_1)\n",
    "print(emb_1.weight)\n",
    "inp =  torch.LongTensor([[1], [2]])\n",
    "print(inp)\n",
    "print(inp.size())\n",
    "embedded = emb_1(inp)\n",
    "embedded.size()\n",
    "print(embedded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('MMCD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bdb4c9c3f61b306428a8735aa29fdb3d47c708c66b6a0572dccc6544bde0e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
